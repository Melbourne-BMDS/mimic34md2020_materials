{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "## What if we used machine learning rather than a rules-based system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo(\"UEm7H8cfz80\", start=2600, end=2708, rel=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Using a Pre-Trained Machine Learning Model\n",
    "So far, we've been using **rule-based methods** to extract concepts from text. An alternative is **statistical NLP**, where you train a machine learning classifier to extract concepts based on annotated datasets.\n",
    "\n",
    "We'll use a model trained on the i2b2 2012 shared task: [**\"Evaluating temporal relations in clinical text\"**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3756273/). This model was trained on data for the first subtask in the shared task, referred to in the challenge as **\"Clinically relevant events\"**. For the purpose of this module, I specifically restricted it to the following labels of **clinical concepts**:\n",
    "- **Problems:** Diagnoses, signs, and symptoms\n",
    "- **Tests:** Lab and vital measurements\n",
    "- **Treatments:** Medications, procedures, and therapies\n",
    "\n",
    "\n",
    "The model has been pre-installed and is available with the name **\"en_info_3700_i2b2_2012\"**. To install on your own machine, run this command to download and install the model:\n",
    "```pip\n",
    "pip install https://github.com/abchapman93/spacy_models/raw/master/releases/en_info_3700_i2b2_2012-0.1.0/dist/en_info_3700_i2b2_2012-0.1.0.tar.gz\n",
    "```\n",
    "\n",
    "We can load this using medSpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using medSpaCy\n",
    "nlp = medspacy.load(\"en_info_3700_i2b2_2012\", enable=['sentencizer', 'tagger', 'parser',\n",
    "                                                      'ner', 'target_matcher', 'context',\n",
    "                                                     'sectionizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what labels will be predicted by the NER component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what concepts are extracted by our model. Any of the target concepts in `doc.ents` will have been extracted by the statistical NER model. MedSpaCy will keep extracting the modifiers and section titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Past Medical History:\n",
    "1. Type II DM\n",
    "2. Afib\n",
    "3. CKD Stage 3\n",
    "\n",
    "Family History:\n",
    "1. Breast Cancer\n",
    "\n",
    "\n",
    "Reason for this examination: Possible pneumonia.\n",
    "\n",
    "IMPRESSION:\n",
    "No evidence of pneumonia.\n",
    "\n",
    "Assessment/Plan:\n",
    "Continue metformin for type 2 dm.\"\"\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- Compared with our rule-based system, how did the clinical NER do with our text? \n",
    "- How could you improve its performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "Our final notebook contains exercises with several clinical concepts which need to be extracted. We'll end by deploying our NLP system to a large corpus of **MIMIC-II** notes and using the structured output for analysis.\n",
    "\n",
    "[nlp-05-clinical-nlp-workshop.ipynb](nlp-05-clinical-nlp-workshop.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
