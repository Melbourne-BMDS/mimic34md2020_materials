{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1752ce061957fd1ce93d2e4db9494b7b29da7935"
   },
   "source": [
    "This material has been adapted by @dcapurro from the Jupyter Notebook developed by:\n",
    "\n",
    "Author: [Yury Kashnitsky](https://yorko.github.io). Translated and edited by [Christina Butsko](https://www.linkedin.com/in/christinabutsko/), [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/), [Anastasia Manokhina](https://www.linkedin.com/in/anastasiamanokhina), Sergey Isaev and [Artem Trunov](https://www.linkedin.com/in/datamove/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8000f32601aff93ebda3e8ca0baea376988a5649"
   },
   "source": [
    "## 1. Demonstration of main Pandas methods\n",
    "Well... There are dozens of cool tutorials on Pandas and visual data analysis. This one will guide us through the basic tasks when you are exploring your data (how deos the data look like?)  \n",
    "\n",
    "**[Pandas](http://pandas.pydata.org)** is a Python library that provides extensive means for data analysis. Data scientists often work with data stored in table formats like `.csv`, `.tsv`, or `.xlsx`. Pandas makes it very convenient to load, process, and analyze such tabular data using SQL-like queries. In conjunction with `Matplotlib` and `Seaborn`, `Pandas` provides a wide range of opportunities for visual analysis of tabular data.\n",
    "\n",
    "The main data structures in `Pandas` are implemented with **Series** and **DataFrame** classes. The former is a one-dimensional indexed array of some fixed data type. The latter is a two-dimensional data structure - a table - where each column contains data of the same type. You can see it as a dictionary of `Series` instances. `DataFrames` are great for representing real data: rows correspond to instances (examples, observations, etc.), and columns correspond to features of these instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e855067a1d281ca6634772513ef918aa1c9224f4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3ae8b8d09f0dd881831253957ca96d086038f7b"
   },
   "source": [
    "We'll demonstrate the main methods in action by analyzing a dataset that is an extract of the MIMIC III Database.\n",
    "\n",
    "Let's read the data (using `read_csv`), and take a look at the first 5 lines using the `head` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f274f88e14b4df01f8f60bd8be5e0cea903a7dd7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/shared/icu_2012.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2f8fc5742d83ec5a110fa56fd967497013bec39"
   },
   "source": [
    "<details>\n",
    "<summary>About printing DataFrames in Jupyter notebooks</summary>\n",
    "<p>\n",
    "In Jupyter notebooks, Pandas DataFrames are printed as these pretty tables seen above while `print(df.head())` is less nicely formatted.\n",
    "By default, Pandas displays 20 columns and 60 rows, so, if your DataFrame is bigger, use the `set_option` function as shown in the example below:\n",
    "\n",
    "```python\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "```\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "Recall that each row corresponds to one patient, an **instance**, and columns are **features** of this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1a98d3e208e59ad0825687ba732f32714fd5e5c"
   },
   "source": [
    "Letâ€™s have a look at data dimensionality, feature names, and feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85347476c8a704b43ddc6b5ec54ac0059b2b740a"
   },
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26e01159ec9dfc2634bbb3be4ccc3ec82c1b01e4"
   },
   "source": [
    "From the output, we can see that the table contains 4000 rows and 79 columns.\n",
    "\n",
    "Now let's try printing out column names using `columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "216df4e9a25d0baa8b506e1ec72df488d78367eb"
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60f8c02d4e9b4ef82f9721fc2fb274ca50e0d6e4"
   },
   "source": [
    "We can use the `info()` method to output some general information about the dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2bcfb060dcbda4fe1720eaf3c2e5c003a891dd77"
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6fac47f7e7bcf060164b1881d8e199973834cd38"
   },
   "source": [
    "`bool`, `int64`, `float64` and `object` are the data types of our features. We see that one feature is logical (`bool`), 3 features are of type `object`, and 16 features are numeric. With this same method, we can easily see if there are any missing values. Here, we can see that there are columns with missing variables because some columns contain less than the 4000 number of instances (or rows) we saw before with `shape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11030a8bd020c6a3a04beb73531e9676160bcab8"
   },
   "source": [
    "The `describe` method shows basic statistical characteristics of each numerical feature (`int64` and `float64` types): number of non-missing values, mean, standard deviation, range, median, 0.25 and 0.75 quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24e1d394f938980403a736421b4cf855ddb8ef8c"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2314370435c6c44da57d4c97ad01ace128047fd5"
   },
   "source": [
    "The `describe` methods only gives us information about numerical variables. Some of these don't really make sense, like the `subject_id` or `gender` but since they are numbers, we are getting summary statistics anyways.\n",
    "\n",
    "In order to see statistics on non-numerical features, one has to explicitly indicate data types of interest in the `include` parameter. We would use `df.describe(include=['object', 'bool'])` but in this case, the dataset only has variables of type `int` and `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7acac4f33f2229215aa7818b10f4dfb1fafd96af"
   },
   "source": [
    "For categorical (type `object`) and boolean (type `bool`) features we can use the `value_counts` method. This also woeks for variables that have been encoded into integers like Gender. Let's have a look at the distribution of `Gender`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eef4f419ac223f320d1841635ffbb816c807fe54"
   },
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78e28e7dbdd84116fe5c30a56f6c649befadd832"
   },
   "source": [
    "Since Gender is encoded in the following way: (0: female, or 1: male)\n",
    "\n",
    "2246 intances are male patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f54ceacde8fe8b61fca39694651c82ba43a5b2c"
   },
   "source": [
    "\n",
    "### Sorting\n",
    "\n",
    "A DataFrame can be sorted by the value of one of the variables (i.e columns). For example, we can sort by *Age* (use `ascending=False` to sort in descending order):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "419200266ac1e7d0e96ba1a20d756c9d87eb2541"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "df.sort_values(by='Age', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad38052b7cc86b6ff5b35907c5a69ed3dacfcdef"
   },
   "source": [
    "We can also sort by multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db028bb799847b257a1107226ec599484596bc1e"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['Age', 'Height'],\n",
    "        ascending=[False, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff41ebcef7b883413530260388df7e23996862ba"
   },
   "source": [
    "### Indexing and retrieving data\n",
    "\n",
    "A DataFrame can be indexed in a few different ways. \n",
    "\n",
    "To get a single column, you can use a `DataFrame['Name']` construction. Let's use this to answer a question about that column alone: **what is the average maximum heart rate of admitted patients in our dataframe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b020796a83bc9e10b1bc8e9c6439fc006302d999"
   },
   "outputs": [],
   "source": [
    "df['HR_max'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8abe3b0982e4599e775f08d8f2feab2b8a702a7b"
   },
   "source": [
    "106 bpm is slightly elevated, but it seems reasonable for an ICU population\n",
    "\n",
    "**Boolean indexing** with one column is also very convenient. The syntax is `df[P(df['Name'])]`, where `P` is some logical condition that is checked for each element of the `Name` column. The result of such indexing is the DataFrame consisting only of rows that satisfy the `P` condition on the `Name` column. \n",
    "\n",
    "Let's use it to answer the question:\n",
    "\n",
    "**What are average values of numerical features for male patients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3712d185e50d44c65128468c603b120b75786c84"
   },
   "outputs": [],
   "source": [
    "df[df['Gender'] == 1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "126e527e04c244c71edd9eac3abcc4a0a8bcd2cb"
   },
   "source": [
    "**What is the average Max Creatinine for patients female patients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "314dfa8e0aeaa0a1d333e32234bd9b3e0a001348"
   },
   "outputs": [],
   "source": [
    "df[df['Gender'] == 0]['Creatinine_max'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69353301d299fd09c3114afef0778693a163418e"
   },
   "source": [
    "DataFrames can be indexed by column name (label) or row name (index) or by the serial number of a row. The `loc` method is used for **indexing by name**, while `iloc()` is used for **indexing by number**.\n",
    "\n",
    "In the first case below, we say *\"give us the values of the rows with index from 0 to 5 (inclusive) and columns labeled from State to Area code (inclusive)\"*. In the second case, we say *\"give us the values of the first five rows in the first three columns\"* (as in a typical Python slice: the maximal value is not included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e16024cbb42c7612a6805ed1442ca68cecd4526f"
   },
   "outputs": [],
   "source": [
    "df.loc[0:5, 'RecordID':'ICUType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0088ea1feeb310133ff979007bbf10f27554faee"
   },
   "outputs": [],
   "source": [
    "df.iloc[0:5, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35d8ce07aeb613e44dbd577ff1b17d4d109a7e5d"
   },
   "source": [
    "If we need the first or the last line of the data frame, we can use the `df[:1]` or `df[-1:]` construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4af7fa312fc6ce80816fea6d0b960b8c01dee9ed"
   },
   "outputs": [],
   "source": [
    "df[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a982c54dd9d60bd4e98e04a19942f6bad1d5d920"
   },
   "source": [
    "\n",
    "### Applying Functions to Cells, Columns and Rows\n",
    "\n",
    "**To apply functions to each column, use `apply()`:**\n",
    "In this example, we will obtain the max value for each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca4613b21459e0adc5c77ee4632cf35d749d4799"
   },
   "outputs": [],
   "source": [
    "df.apply(np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8189ed0376dd712ccd2357081e224087f7d3d0aa"
   },
   "source": [
    "The `map` method can be used to **replace values in a column** by passing a dictionary of the form `{old_value: new_value}` as its argument. Let's change the values of female and male for the corresponding `strings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c01e23976470fd6efc3604e4d755e93ac11c3eac"
   },
   "outputs": [],
   "source": [
    "d = {0 : 'Female', 1 : 'Male'}\n",
    "df['Gender'] = df['Gender'].map(d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4a2e2296e26b94ef6e8f0f457b13c42a5559568"
   },
   "source": [
    "The same thing can be done with the `replace` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "624736c649a9875bfee158df92238c6348f5a6b0"
   },
   "outputs": [],
   "source": [
    "d2 = {1: 'Coronary Care Unit', 2: 'Cardiac Surgery Recovery Unit', 3: 'Medical ICU', 4: 'Surgical ICU'}\n",
    "df = df.replace({'ICUType': d2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also replace missing values when it is necessary. For that we use the `filna()` methohd. In this case, we will replace them in the Mechanical Ventilation column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MechVent_min'].fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "Histograms are an important tool to understand the distribution of your variables. It can help you detect errors in the data, like extreme or unplausible values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly see that the distribution of age is not normal. Let's look at Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Na_max'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a lot of resolution here. Let's increase the number of bins to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Na_max'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! It is easy to see that this is approximately a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22f7916fb05500116fdd6e52b86bf7949912bd9c"
   },
   "source": [
    "\n",
    "### Grouping\n",
    "\n",
    "In general, grouping data in Pandas works as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "850ace3defaca6b72ef976c86a5020c4ed8f65b3"
   },
   "source": [
    "\n",
    "```python\n",
    "df.groupby(by=grouping_columns)[columns_to_show].function()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ac45d322f049449259ff21197e9977e220e82d1"
   },
   "source": [
    "\n",
    "1. First, the `groupby` method divides the `grouping_columns` by their values. They become a new index in the resulting dataframe.\n",
    "2. Then, columns of interest are selected (`columns_to_show`). If `columns_to_show` is not included, all non groupby clauses will be included.\n",
    "3. Finally, one or several functions are applied to the obtained groups per selected columns.\n",
    "\n",
    "Here is an example where we group the data according to `Gender` variable and display statistics of three columns in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "180e6b3d26c8adc52e46d8ab82dad34f9a49e234"
   },
   "outputs": [],
   "source": [
    "columns_to_show = ['Na_max', 'K_max', \n",
    "                   'HCO3_max']\n",
    "\n",
    "df.groupby(['Gender'])[columns_to_show].describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fc26768e62869d3ac4f1c0c379356a642240c7f"
   },
   "source": [
    "Letâ€™s do the same thing, but slightly differently by passing a list of functions to `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e87a8f4b10035128312771fc7e802f1bb660b4c"
   },
   "outputs": [],
   "source": [
    "columns_to_show = ['Na_max', 'K_max', \n",
    "                   'HCO3_max']\n",
    "\n",
    "df.groupby(['Gender'])[columns_to_show].agg([np.mean, np.std, np.min, \n",
    "                                            np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "221a34086734d3b52deccfda2db2edfb6f1b92a5"
   },
   "source": [
    "\n",
    "### Summary tables\n",
    "\n",
    "Suppose we want to see how the observations in our sample are distributed in the context of two variables - `Gender` and `ICUType`. To do so, we can build a **contingency table** using the `crosstab` method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebcff1fdb2e6805fa186a0f5c27b46655222e9c2"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['Gender'], df['ICUType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7f0851cc14ce07d75871d1305b31e839a253b72"
   },
   "source": [
    "This will resemble **pivot tables** to those familiar with Excel. And, of course, pivot tables are implemented in Pandas: the `pivot_table` method takes the following parameters:\n",
    "\n",
    "* `values` â€“ a list of variables to calculate statistics for,\n",
    "* `index` â€“ a list of variables to group data by,\n",
    "* `aggfunc` â€“ what statistics we need to calculate for groups, ex. sum, mean, maximum, minimum or something else.\n",
    "\n",
    "Let's take a look at the average number of day, evening, and night calls by area code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81d2edd79f7c3e9a4b77e38ebf0fa27b39f5e7c5"
   },
   "outputs": [],
   "source": [
    "df.pivot_table(['TroponinI_max', 'TroponinT_max'],\n",
    "               ['ICUType'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea35f7ad664ff32785231dcae2292e9a66b28b90"
   },
   "source": [
    "Nothing surprising here, patients in the coronary/cardiac units have higher values of Troponins.\n",
    "\n",
    "### DataFrame transformations\n",
    "\n",
    "Like many other things in Pandas, adding columns to a DataFrame is doable in many ways.\n",
    "\n",
    "For example, if we want to calculate the change in creatinine, let's create the `Delta_creatinine` Series and paste it into the DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d1214ac2a3d0e7e0f3d265018985eacef2f25b3"
   },
   "outputs": [],
   "source": [
    "Delta_creatinine = df['Creatinine_max'] - df['Creatinine_min']\n",
    "\n",
    "df.insert(loc=len(df.columns), column='Delta_creatinine', value=Delta_creatinine) \n",
    "# loc parameter is the number of columns after which to insert the Series object\n",
    "# we set it to len(df.columns) to paste it at the very end of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "244a645e9676b8bd2546bc84926cb9e43124e4c2"
   },
   "source": [
    "It is possible to add a column more easily without creating an intermediate Series instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5ec80ecb3b2e917834ccfb6cb0a76aced20315f"
   },
   "outputs": [],
   "source": [
    "df['Delta_BUN'] = df['BUN_max'] - df['BUN_min']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83e0b3c996775535de55a8773bdd7dee215e2a3b"
   },
   "source": [
    "To delete columns or rows, use the `drop` method, passing the required indexes and the `axis` parameter (`1` if you delete columns, and nothing or `0` if you delete rows). The `inplace` argument tells whether to change the original DataFrame. With `inplace=False`, the `drop` method doesn't change the existing DataFrame and returns a new one with dropped rows or columns. With `inplace=True`, it alters the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48fbc2e42a623ee78f9e2d9222186387561bbb0a"
   },
   "outputs": [],
   "source": [
    "# get rid of just created columns\n",
    "df.drop(['Delta_creatinine', 'Delta_BUN'], axis=1, inplace=True) \n",
    "# and hereâ€™s how you can delete rows\n",
    "df.drop([1, 2]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "482e5e694de9c2173dd607a2821c54d704bc88ea"
   },
   "source": [
    "## 2. Exploring some associations\n",
    "\n",
    "\n",
    "Let's see how mechanical ventilation is related to Gender. We'll do this using a `crosstab` contingency table and also through visual analysis with `Seaborn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bc65b91a9041032168dfd50d5fab097c003d9c0"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['MechVent_min'], df['Gender'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c809a62f4d1077993a0f0f2d36d1066c108ca23d"
   },
   "outputs": [],
   "source": [
    "# some imports to set up plotting \n",
    "import matplotlib.pyplot as plt\n",
    "# pip install seaborn \n",
    "import seaborn as sns\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the plot that will show us the counts of mechanically ventilated patients by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae3bb6cdde2a6d72112e6076d92b35f2f2caaa3e"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Gender', hue='MechVent_min', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1134a7f1fe7a5c8dae399a84f58611043f6e757"
   },
   "source": [
    "We see that th number (and probably the proportion) of mechanically ventilated patients is greater among males. \n",
    "\n",
    "Next, let's look at the same distribution but comparing the different ICU types: Let's also make a summary table and a picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75cf7fe86ae75e01d49a07fb52fe5c8ce1c6a334"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['ICUType'], df['MechVent_min'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc0a6cb1fb72cc66bc1d7c33301b3ab0d2c7d81b"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='ICUType', hue='MechVent_min', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the proportion of patients ventilated and not ventilated is very different across the different types of ICUs. That is particularly true in the cardiac surgery recovery unit. Can you think of a reason why that might be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "edcffb69d14aa3b9d3d8a49d145900011d35829f"
   },
   "source": [
    "## 3. Some useful resources\n",
    "\n",
    "* [\"Merging DataFrames with pandas\"](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/tutorials/merging_dataframes_tutorial_max_palko.ipynb) - a tutorial by Max Plako within mlcourse.ai (full list of tutorials is [here](https://mlcourse.ai/tutorials))\n",
    "* [\"Handle different dataset with dask and trying a little dask ML\"](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/tutorials/dask_objects_and_little_dask_ml_tutorial_iknyazeva.ipynb) - a tutorial by Irina Knyazeva within mlcourse.ai\n",
    "* Main course [site](https://mlcourse.ai), [course repo](https://github.com/Yorko/mlcourse.ai), and YouTube [channel](https://www.youtube.com/watch?v=QKTuw4PNOsU&list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX)\n",
    "* Official Pandas [documentation](http://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "* Course materials as a [Kaggle Dataset](https://www.kaggle.com/kashnitsky/mlcourse)\n",
    "* Medium [\"story\"](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-1-exploratory-data-analysis-with-pandas-de57880f1a68) based on this notebook\n",
    "* If you read Russian: an [article](https://habrahabr.ru/company/ods/blog/322626/) on Habr.com with ~ the same material. And a [lecture](https://youtu.be/dEFxoyJhm3Y) on YouTube\n",
    "* [10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "* [Pandas cheatsheet PDF](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)\n",
    "* GitHub repos: [Pandas exercises](https://github.com/guipsamora/pandas_exercises/) and [\"Effective Pandas\"](https://github.com/TomAugspurger/effective-pandas)\n",
    "* [scipy-lectures.org](http://www.scipy-lectures.org/index.html) â€” tutorials on pandas, numpy, matplotlib and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
