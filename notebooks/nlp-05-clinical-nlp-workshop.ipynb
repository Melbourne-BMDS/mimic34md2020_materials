{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook, we'll put together all of the NLP tools we've learned and apply them to several clinical problems:\n",
    "\n",
    "1. Detecting evidence of surgical site infections (SSIs) and body location\n",
    "2. Identify texts with positive COVID-19 cases\n",
    "3. Apply our NLP pipeline to MIMIC data and analyze the results using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.context import ConTextItem\n",
    "from medspacy.visualization import visualize_ent, visualize_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of Model\n",
    "For Tasks #1-2, which are short and include very specific concepts, we'll load a blank model and add target rules to match the concepts. Task #3 is quite long and will include many different concepts. This is exactly the kind of scenario when we would want to use a pre-trained machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()\n",
    "# nlp = medspacy.load(\"en_info_3700_i2b2_2012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher = nlp.get_pipe(\"target_matcher\")\n",
    "context = nlp.get_pipe(\"context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Surgical site infection\n",
    "Patient safety measures require identifying adverse outcomes of medical treatment, such as surgical site infections (SSIs). In this exercise, we will identify evidence of SSIs from radiology exams. \n",
    "\n",
    "- Add target rules to match any mention of evidence of SSI such as **\"fluid collection\"** or **\"abscess\"**\n",
    "- Add target rules to match any body location\n",
    "- Add context rules to identify any additional modifiers, such as negation or uncertainty\n",
    "\n",
    "See this manuscript: [Detecting Evidence of Intra-abdominal Surgical Site Infections From Radiology Reports Using Natural Language Processing](https://pubmed.ncbi.nlm.nih.gov/29854116/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Fluid collection is seen in the abdomen.\",\n",
    "    \"There is no evidence of fluid collection.\",\n",
    "    \"PURPOSE OF EXAM: Rule out abscess.\",\n",
    "    \"Hematomas are seen around in the right lower quadrant.\",\n",
    "    \"No drainable collection is noted at this time.\",\n",
    "    \"Post-surgical enhancing fluid collections, most notable right lower quadrant and left pelvis.\",\n",
    "    \"please assess for possible ir drainage if abscess present.\",\n",
    "    \"Intraloop fluid collection with air-fluid level, might represent contained rupture or intraloop abscess.\",\n",
    "    \"No evidence of intra-abdominal abscess.\",\n",
    "    \"Right paracolic and anterior abdominal fluid collections with rim enhacement likely representing abscesses amenable to drainage.\",\n",
    "    \"r/o infiltrate, fluid collection\",\n",
    "    \"No fluid collection is identified within the abdomen and pelvis.\",\n",
    "    \"no fluid collection is seen around the anastamosis site\",\n",
    "    \"36 year old woman with nectrotzing pancreatitis and intraabdominal collections.\",\n",
    "    \"REASON FOR THIS EXAMINATION: CT abd/pelvis to access for dihiscence or abcess / fluid collection.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rules = [\n",
    "    TargetRule(____, \"SSI\"),\n",
    "    # ...\n",
    "    \n",
    "    TargetRule(____, \"BODY_LOC\"),\n",
    "    # ...\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher.add(target_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_item_data = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.add(context_item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scroll through the results and see if you extracted all of the relevant information. If your model misses any, go back and add them to your rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(docs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dep(docs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. COVID-19\n",
    "In this exercise, we will look for evidence of COVID-19 from clinical text. See this manuscript describing a similar like this: [A Natural Language Processing System for National\n",
    "COVID-19 Surveillance in the US Department of Veterans Affairs](https://openreview.net/pdf?id=ZQ_HvBxcdCv)\n",
    "\n",
    "- Add target rules to extract any mentions of COVID-19 or synonyms\n",
    "- Add context rules to identify any modifiers such as **\"NEGATED_EXISTENCE\"**, **\"UNCERTAIN\"**, or **\"POSITIVE_EXISTENCE\"** (ie, \"confirmed\" or \"diagnosed with\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()\n",
    "target_matcher = nlp.get_pipe(\"target_matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Patient admitted to hospital for respiratory failure secondary to COVID-19.\",\n",
    "    \"The patient reports that they have been diagnosed with COVID-19\",\n",
    "    \"Requested that patient be screened for novel coronavirus via telephone\",\n",
    "    \"Lab Results: SARS-COV-2 DETECTED\",\n",
    "    \"Patient does not have COVID-19\",\n",
    "    \"This encounter is done over the telephone secondary to COVID-19 precautions.\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher = nlp.get_pipe(\"target_matcher\")\n",
    "context = nlp.get_pipe(\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rules = [\n",
    "    TargetRule(___, \"COVID-19\"),\n",
    "    # ...\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher.add(target_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = nlp.get_pipe(\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = [\n",
    "    ConTextItem(____, \"POSITIVE_EXISTENCE\"),\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.add(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(docs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dep(docs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Process full documents from MIMIC-II\n",
    "In this exercise,  We will then take our extracted entities, convert them into structured data, and analyze the results using pandas.\n",
    "\n",
    "Now that you've fine-tuned and improved your model, we're ready to run it on the entire dataset and analyze it! In this step, we'll show how you can use NLP to convert text to **structured** data, which you can then analyze in the same way that we previously analyzed structured EHR data like **labs** and **vitals**. We'll first apply our NLP system to a large corpus of discharge summaries from MIMIC-II. Then we'll extract all of the entities from our docs and convert them into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our machine learning model\n",
    "nlp = medspacy.load(\"en_info_3700_i2b2_2012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matcher = nlp.get_pipe(\"target_matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host=\"35.233.174.193\",port=3306,\n",
    "                           user=getpass.getpass(\"Enter username for MIMIC2 database\"),\n",
    "                           passwd=getpass.getpass(\"Enter password for MIMIC2 database\"),\n",
    "                           db='mimic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Change the query below to pull as many documents as you like. Using more documents will give you more interesting and relevant results, but will also take longer to process with `nlp`. I recommend using 100-1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT subject_id, text\n",
    "FROM noteevents\n",
    "WHERE category = 'DISCHARGE_SUMMARY'\n",
    "LIMIT 10;\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "docs = list(nlp.pipe(df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to structured data\n",
    "The function below will take the attributes of an entity and return a dictionary. We can then take a list of dictionaries and convert them to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_to_dict(ent):\n",
    "    d = {}\n",
    "    d[\"text\"] = ent.lower_\n",
    "    d[\"label\"] = ent.label_\n",
    "    d[\"sent\"] = ent.sent.text\n",
    "    \n",
    "    # ConText attributes\n",
    "    d[\"is_negated\"] = ent._.is_negated\n",
    "    d[\"is_historical\"] = ent._.is_historical\n",
    "    d[\"is_uncertain\"] = ent._.is_uncertain\n",
    "    d[\"is_family\"] = ent._.is_family\n",
    "    d[\"is_hypothetical\"] = ent._.is_hypothetical\n",
    "    \n",
    "    # Section\n",
    "    d[\"section_title\"] = ent._.section_title\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_data = []\n",
    "for doc in docs:\n",
    "    for ent in doc.ents:\n",
    "        ents_data.append(ent_to_dict(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df = pd.DataFrame(ents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import some visualization modules to visualize our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #1: What is the distribution of entity labels?\n",
    "Generate the count of values in the **\"label\"** column using the pandas `value_counts()` method. Then plot these values as a bar plot to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counts\n",
    "label_counts = ents_df[\"label\"].____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2ae8719fe51f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2ae8719fe51f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ____.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Now plot the top 10\n",
    "____.head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #2: What problems occur most often in the PMH?\n",
    "Use pandas filtering to filter to rows where the section title is **\"past medical history\"** and the label is **\"PROBLEM\"**. Then use the `value_counts()` method to get counts of values in the **\"text\"** column. Then sort the values to see what the most common historical conditions are.\n",
    "\n",
    "### Bonus\n",
    "Plot the top 10 PMH problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, filter to rows where \"label\" == \"PROBLEM\"\n",
    "pmh = ents_df[ents_df[\"label\"] == ____]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter to rows where the section_title is \"past_medical_history\" \n",
    "pmh = pmh[pmh[____] == \"past_medical_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the counts of values in the \"text\" column\n",
    "pmh = pmh[____].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmh.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pmh.head(10).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #3: What problems occur most often in the family history?\n",
    "Filter the dataframe to see which problems occur most often in a patient's family history. This can be either:\n",
    "- The problem occured in the **\"family_history\"** section; or\n",
    "- The problem has a context attribute of **\"is_family\" == True**\n",
    "\n",
    "Then sort to find which problems occur most frequently in family history.\n",
    "\n",
    "### Bonus\n",
    "Plot the top 10 FH problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, filter to rows where \"label\" == \"PROBLEM\"\n",
    "fh = ents_df[ents_df[____] == ____]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, filter to rows where is_family is True or section_title = \"family_history\"\n",
    "fh = fh[(fh[\"is_family\"] == ____) | (fh[____] == ____)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the distinct counts\n",
    "fh = fh[\"text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fh.head(10).plot.barh()\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
